{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of Untitled.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhargavi19/fake-review-detection/blob/main/Copy_of_Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfTjnSzhaLYD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from nltk import bigrams,trigrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from textblob import TextBlob\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Ml6oT-pPaLYG",
        "outputId": "f8a99807-6185-431c-aea6-c56bbcb2f6c7"
      },
      "source": [
        "s = \"inexpensive tablet for him to use and learn on, step up from the nabi. he was thrilled with it, learn how to skype on it already...\"\n",
        "s = ' '.join([word for word in s.split() if word not in all_stop_words])\n",
        "s = ' '.join([st.stem(word) for word in s.split()])\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-10899f53f07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"inexpensive tablet for him to use and learn on, step up from the nabi. he was thrilled with it, learn how to skype on it already...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_stop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-10899f53f07b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"inexpensive tablet for him to use and learn on, step up from the nabi. he was thrilled with it, learn how to skype on it already...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_stop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_stop_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYKjS0tFaLYH"
      },
      "source": [
        "file1 = open(\"YelpChi/output_review_yelpResData_NRYRcleaned.txt\")\n",
        "data1 = []\n",
        "data4 = []\n",
        "all_stop_words = stopwords.words('english')\n",
        "st = PorterStemmer()\n",
        "for row in file1:\n",
        "    # temp = row.split()\n",
        "    row = re.sub('[^a-zA-Z0-9 \\n\\..]', '', row)\n",
        "    a,b = TextBlob(row).sentiment\n",
        "    row = ' '.join([word for word in row.split() if word not in all_stop_words])\n",
        "    row = ' '.join([st.stem(word) for word in row.split()])\n",
        "    data4.append([a,b])\n",
        "    data1.append(row)\n",
        "\n",
        "file1.close()\n",
        "# print(data1[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMYep4oTaLYI"
      },
      "source": [
        "file2 = open(\"YelpChi/output_meta_yelpResData_NRYRcleaned.txt\")\n",
        "data2 = []\n",
        "data3 = []\n",
        "for row in file2:\n",
        "    temp = row.split()[4]\n",
        "    data3.append(int(row.split()[-1]))\n",
        "    if temp == \"N\":\n",
        "        data2.append(1)\n",
        "    else:\n",
        "        data2.append(0)\n",
        "file2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJu9F7FsaLYI"
      },
      "source": [
        "data3 = np.asarray(data3).reshape(-1,1)\n",
        "data4 = np.asarray(data4)\n",
        "Y = np.asarray(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "g1uUC4ouaLYI"
      },
      "source": [
        "some = X[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okw1fTdxaLYJ"
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(stop_words='english')\n",
        "X = tfidf_vector.fit_transform(data1)\n",
        "# xvt_test = tfidf_vector.transform(x_test[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS5JBFO2aLYJ"
      },
      "source": [
        "svd = TruncatedSVD(n_components = 100)\n",
        "X = svd.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p3w449taLYJ"
      },
      "source": [
        "X = np.hstack((X,data3,data4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XOS7RDsaLYK"
      },
      "source": [
        "xvt_train = X[:5000]\n",
        "y_train = Y[:5000]\n",
        "xvt_test = X[5000:]\n",
        "y_test = Y[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ8tPMA_aLYK"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvYLYTchaLYK"
      },
      "source": [
        "#trying with random forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(xvt_train,y_train)\n",
        "\n",
        "y_pred=rfc.predict(xvt_test)\n",
        "score = accuracy_score(y_pred, y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lHX_rTKaLYL"
      },
      "source": [
        "# with count vectorization\n",
        "bigram_vector = CountVectorizer(ngram_range=(2, 2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "X_bi = bigram_vector.fit_transform(data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AEY59jkaLYM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9zxCNLTaLYN"
      },
      "source": [
        "\n",
        "# xvc_test = bigram_vector.transform(x_test)  #.todense()\n",
        "\n",
        "rfc1 = RandomForestClassifier()\n",
        "rfc1.fit(xvc_train,y_train)\n",
        "\n",
        "y_pred1=rfc1.predict(xvc_test)\n",
        "score1 = rfc1.score(xvc_test, y_test)\n",
        "print(score1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TiRb2WbaLYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhdqwb8QaLYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YSRzBQSaLYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOKAuRhGaLYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T87AYUeeaLYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}